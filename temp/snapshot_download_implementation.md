# Переход на `snapshot_download` для надёжной загрузки модели

## Проблема

При попытке загрузки модели через `SentenceTransformer()` возникали таймауты:

```
ReadTimeoutError: Read timed out. (read timeout=10)
```

### Причины:

1. **Малый таймаут** - 10 секунд недостаточно для файла 470 MB
2. **Сложные редиректы** - HuggingFace использует CDN (CloudFront) и XetHub
3. **Старый механизм** - `SentenceTransformer()` использует базовые HTTP запросы

### Пример проблемного редиректа:

```
https://huggingface.co/.../model.safetensors
  ↓ 302
https://cas-bridge.xethub.hf.co/...?X-Amz-Algorithm=...
```

Длинные подписанные URL с временными токенами, которые плохо обрабатываются простыми загрузчиками.

## Решение: `snapshot_download` от HuggingFace Hub

### Преимущества:

✅ **Умные таймауты** - автоматически адаптируется к размеру файла  
✅ **Обработка редиректов** - понимает CDN, подписанные URL, XetHub  
✅ **Докачка при обрыве** - `resume_download=True`  
✅ **Параллельная загрузка** - несколько файлов одновременно  
✅ **ETag и Range** - эффективное использование пропускной способности  
✅ **Retry механизм** - автоматические повторы при сбоях  

### Реализация:

```python
from huggingface_hub import snapshot_download

# Увеличиваем таймаут до 5 минут на файл
os.environ['HF_HUB_DOWNLOAD_TIMEOUT'] = '300'

# Загружаем модель с докачкой и параллелизмом
local_dir = await asyncio.to_thread(
    snapshot_download,
    repo_id="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
    cache_dir=str(cache_dir.parent),
    resume_download=True,  # ⭐ Докачка при обрыве
    max_workers=4,         # ⭐ Параллельная загрузка
    local_files_only=False
)
```

### Изменённые файлы:

1. **`src/application/web/routes/model_management.py`**
   - Заменён `SentenceTransformer()` на `snapshot_download()`
   - Увеличен таймаут с 10 до 300 секунд
   - Добавлена параллельная загрузка (`max_workers=4`)
   - Использован `asyncio.to_thread()` для неблокирующей загрузки

2. **`pyproject.toml`**
   - Добавлена зависимость `huggingface-hub = "^0.20.0"`

## Как работает новая загрузка:

### Прогресс:

```
 5%  - Начинаю загрузку модели...
10%  - Подключение к HuggingFace Hub...
15%  - Настройка загрузки...
20%  - Загрузка файлов модели (~470 MB)...
25%  - Скачивание модели... (5-15 минут)
      ↓ [snapshot_download работает здесь]
80%  - Модель скачана, инициализация...
85%  - Проверка работоспособности...
92%  - Тестирование эмбеддингов...
98%  - Финализация...
100% - ✅ Модель готова!
```

### Докачка при обрыве:

Если загрузка прервётся (сеть, таймаут), при повторной попытке `snapshot_download`:
1. Проверит ETag существующих файлов
2. Загрузит только недостающие части
3. Не будет качать файлы заново

### Параллельная загрузка:

Модель состоит из нескольких файлов:
- `model.safetensors` (470 MB)
- `config.json`
- `tokenizer_config.json`
- `vocab.txt`
- и другие

`max_workers=4` загружает 4 файла параллельно → быстрее!

## Технические детали

### Таймауты:

```python
os.environ['HF_HUB_DOWNLOAD_TIMEOUT'] = '300'  # 5 минут на файл
```

**Расчёт:** 470 MB / 1 MB/s = 470 сек ≈ 8 минут  
**Таймаут 300 сек** достаточен для скорости >1.5 MB/s

### AsyncIO интеграция:

```python
await asyncio.to_thread(snapshot_download, ...)
```

Загрузка выполняется в отдельном потоке → не блокирует FastAPI event loop.

### Кэш-директория:

```python
cache_dir=str(cache_dir.parent)  # /root/.cache/huggingface
```

HuggingFace Hub сам создаст правильную структуру:
```
/root/.cache/huggingface/hub/
└── models--sentence-transformers--paraphrase-multilingual-MiniLM-L12-v2/
    ├── snapshots/
    │   └── [commit-hash]/
    │       ├── model.safetensors
    │       ├── config.json
    │       └── ...
    └── refs/
        └── main
```

## Сравнение подходов

| Характеристика | `SentenceTransformer()` | `snapshot_download()` |
|----------------|-------------------------|----------------------|
| Таймаут | 10 сек | 300 сек (настраиваемый) |
| Редиректы | Базовые | Умные (CDN, подписанные URL) |
| Докачка | ❌ Нет | ✅ Есть |
| Параллельность | ❌ Нет | ✅ Да (4 потока) |
| Retry | Ограниченный | Автоматический |
| Прогресс | Не виден | Можно отслеживать |

## Результат

После обновления:
- ✅ Модель загружается даже при медленном интернете
- ✅ Можно прервать и продолжить загрузку
- ✅ Быстрее благодаря параллелизму
- ✅ Надёжнее благодаря retry и умным редиректам
- ✅ Прозрачный прогресс для пользователя

## Как проверить

После деплоя попробуйте загрузить модель через `/admin/model/`.

Должно работать даже при:
- Медленном интернете (<1 MB/s)
- Нестабильном соединении
- Сложных CDN редиректах

---

**Дата:** 20.10.2025  
**Автор идеи:** Пользователь (отличная диагностика!)  
**Статус:** Реализовано

