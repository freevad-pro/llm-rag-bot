# Production Docker Compose конфигурация
# Архитектура: 3 контейнера
# - app: FastAPI сервер (API, админка, health checks)
# - bot: Telegram бот (отдельный процесс)
# - postgres: База данных
#
# Отличия от dev версии:
# - Нет volume для hot reload кода
# - Переменные окружения из внешнего .env файла
# - Данные хранятся на хосте (не в Docker volumes)
# - Health checks для всех сервисов
# - Restart policies для автовосстановления

services:
  app:
    build: .
    ports:
      - "8000:8000"
    env_file:
      - /opt/llm-bot/config/.env
    environment:
      # Принудительная установка критичных переменных (приоритет над системными)
      DEBUG: "false"
      ENVIRONMENT: "production"
      # Отключаем Telegram бота в FastAPI контейнере (работает только в отдельном bot контейнере)
      DISABLE_TELEGRAM_BOT: "true"
    depends_on:
      postgres:
        condition: service_healthy
    volumes:
      # Только данные, БЕЗ исходного кода!
      - /opt/llm-bot/data/chroma:/app/data/chroma
      - /opt/llm-bot/data/uploads:/app/data/uploads
      - /opt/llm-bot/data/logs:/app/logs
      # Монтируем .env файл для синхронизации изменений
      - /opt/llm-bot/config/.env:/app/.env
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "python", "-c", "import requests; requests.get('http://localhost:8000/health', timeout=10)"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    labels:
      - "com.docker.compose.service=llm-bot-app"
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  bot:
    build: .
    command: python -m src.main bot
    env_file:
      - /opt/llm-bot/config/.env
    environment:
      DEBUG: "false"
      ENVIRONMENT: "production"
    depends_on:
      postgres:
        condition: service_healthy
    volumes:
      - /opt/llm-bot/data/chroma:/app/data/chroma
      - /opt/llm-bot/data/uploads:/app/data/uploads
      - /opt/llm-bot/data/logs:/app/logs
      # Монтируем .env файл для синхронизации изменений
      - /opt/llm-bot/config/.env:/app/.env
    restart: unless-stopped
    labels:
      - "com.docker.compose.service=llm-bot-bot"
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  postgres:
    image: postgres:15
    environment:
      POSTGRES_DB: catalog_db
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-password}
      POSTGRES_INITDB_ARGS: "--encoding=UTF8 --locale=C"
    volumes:
      - /opt/llm-bot/data/postgres:/var/lib/postgresql/data
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d catalog_db"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    labels:
      - "com.docker.compose.service=llm-bot-postgres"
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    # Не открываем порт наружу в production (только внутри Docker network)
    # ports:
    #   - "5432:5432"

# Удаляем named volumes - используем только host volumes
# volumes:
#   postgres_data:
